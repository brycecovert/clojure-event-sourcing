export { default as theme } from './theme';
import { default as SyntaxHighlighter } from 'react-syntax-highlighter';
import { default as github } from 'react-syntax-highlighter/dist/styles/hljs/github';

# Event-sourced systems
with Clojure

---

import { Appear } from 'mdx-deck'

# Event-sourced systems
## definition
<ul>
<Appear>
<li> event - something that occurs in a certain place during a particular interval of time</li>
<li>source (verb) - to give or trace the source for</li>
<li>event-sourced system = a system that traces everything that happens, for all time </li>
<li>event-sourced system = append-only ledger of events, materialized views</li>
</Appear>
</ul>

---

# Why event-sourced systems?
* see datomic
* make data available; limit point-to-point communication
* simulatable, replayable, reconcilable

---

# How event-sourced systems?

* Kafka, Kafka Streams, Jackdaw

---

# Prior art

* Transducers?
* RX 
* Samza

---

# Kafka

---

# Kafka architecture

![Topic](https://kafka.apache.org/22/images/log_anatomy.png)

---

# Producers / Consumers

![Topic](https://kafka.apache.org/22/images/log_anatomy.png)

---

# Kafka Streams

---

# Jackdaw

---

# Events

<SyntaxHighlighter language='clojure' style={github} wrapLines={true} >
{`([{:flight "UA1432"} {:event :departed}]
 [{:flight "UA1432"} {:event :arrived}])`}

</SyntaxHighlighter>

---

# A simple example

<SyntaxHighlighter language='clojure' style={github} wrapLines={true} >
{`(-> builder
      (j/kstream (topic-config "flights"  ))
      (j/group-by-key)
      (j/reduce (fn [ v1 v2]
                  (merge v1 v2))
                (topic-config "flights"))
      (j/to-kstream)
      (j/to (topic-config "flight-results")))`}

</SyntaxHighlighter>

---

import { Notes } from 'mdx-deck';

# Best Practices
* Determinism
* Corrections
* Topic hierachy
* Transactionality
* Event structure
* Retention

<Notes>
* Determinism - you can't guarantee order across different partitions. Spread your keys out as much as possible, while ensuring order is respected. PartitionKey can be separate from the event's key.
* Determinism - Turn the process off for a week. Same results as leaving it on?
* Corrections You can't delete data. Your systems, and downstream systems need to be able to handle corrections. At least two ways - an event with the same id is a corrected event, or you can proactively void events 
* Topic hierarchy - Observations and Decisions shouldn't be sourced from the same topic. You can't simulate. Prefer to merge the streams. 
* Transactionality - Exactly-once delivery
* Event structure - State of the world is a graph, changes or updates to that graph. Small event domain = customized events. Large, complex, event domain = be explicit about the graph changes for your consumers
* Retention - Kafka by default keeps data for a certain amount of time. If you can't store all history, I recommend using compaction, will make sure that there is always at least one record per key
</Notes>

---

# The end

---
Notes:
+ Create sample for producing and consuming only
+ Create use case for replay or simulation. Measure outcomes from better algorithm;
